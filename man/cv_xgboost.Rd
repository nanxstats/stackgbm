% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/cv_xgboost.R
\name{cv_xgboost}
\alias{cv_xgboost}
\title{xgboost - parameter tuning and model selection with k-fold cross-validation and grid search}
\usage{
cv_xgboost(
  x,
  y,
  nfolds = 5L,
  seed = 42,
  verbose = TRUE,
  nrounds = c(100, 200, 500, 1000),
  max_depth = c(3, 5, 7, 9),
  learning_rate = c(0.01, 0.05, 0.1, 0.2),
  ncpus = parallel::detectCores()
)
}
\arguments{
\item{x}{Predictor matrix}

\item{y}{Response vector}

\item{nfolds}{Number of folds. Default is 5.}

\item{seed}{Random seed for reproducibility}

\item{verbose}{Show progress?}

\item{nrounds}{Grid vector for the parameter \code{nrounds}.}

\item{max_depth}{Grid vector for the parameter \code{max_depth}.}

\item{learning_rate}{Grid vector for the parameter \code{learning_rate}.}

\item{ncpus}{Number of CPU cores to use. Defaults is all detectable cores.}
}
\value{
A data frame containing the complete tuning grid and the AUC values,
with the best parameter combination and the highest AUC value.
}
\description{
xgboost - parameter tuning and model selection with k-fold cross-validation and grid search
}
\examples{
# check the vignette for code examples
}
