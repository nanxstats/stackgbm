% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/stackgbm-package.R
\docType{package}
\name{stackgbm-package}
\alias{stackgbm-package}
\title{stackgbm: Stacked Gradient Boosting Machines}
\description{
\if{html}{\figure{logo.png}{options: style='float: right' alt='logo' width='120'}}

A minimalist implementation of model stacking by Wolpert (1992) \doi{10.1016/S0893-6080(05)80023-1} for boosted tree models built by 'xgboost' \doi{10.1145/2939672.2939785}, 'lightgbm' \url{https://dl.acm.org/doi/10.5555/3294996.3295074}, and 'catboost' \url{https://dl.acm.org/doi/abs/10.5555/3327757.3327770}. A classic, two-layer stacking model is implemented, where the first layer generates features using gradient boosting trees, and the second layer employs a logistic regression model that uses these features as inputs. It aims to provide a simple and efficient way to combine multiple gradient boosting models to improve predictive model performance and robustness.
}
\seealso{
Useful links:
\itemize{
  \item \url{https://nanx.me/stackgbm/}
  \item \url{https://github.com/nanxstats/stackgbm}
  \item Report bugs at \url{https://github.com/nanxstats/stackgbm/issues}
}

}
\author{
\strong{Maintainer}: Nan Xiao \email{me@nanx.me} (\href{https://orcid.org/0000-0002-0250-5673}{ORCID}) [copyright holder]

}
\keyword{internal}
