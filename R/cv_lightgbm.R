#' lightgbm - parameter tuning and model selection with k-fold cross-validation
#' and grid search
#'
#' @param x Predictor matrix.
#' @param y Response vector.
#' @param params Parameter grid generated by [cv_param_grid()].
#' @param n_folds Number of folds. Default is 5.
#' @param n_threads The number of parallel threads for
#'   fitting individual models. Default is 1.
#'
#' @return
#' A data frame containing the complete tuning grid and the AUC values,
#' with the best parameter combination and the highest AUC value.
#'
#' @importFrom pROC auc
#' @importFrom foreach foreach
#' @importFrom doFuture "%dofuture%"
#' @importFrom progressr progressor
#'
#' @export
#'
#' @examplesIf is_installed_lightgbm()
#' library(doFuture)
#' library(progressr)
#'
#' sim_data <- msaenet::msaenet.sim.binomial(
#'   n = 100,
#'   p = 10,
#'   rho = 0.6,
#'   coef = rnorm(5, mean = 0, sd = 10),
#'   snr = 1,
#'   p.train = 0.8,
#'   seed = 42
#' )
#'
#' set.seed(42)
#' plan(sequential)
#'
#' params <- suppressWarnings(
#'   cv_lightgbm(
#'     sim_data$x.tr,
#'     sim_data$y.tr,
#'     params = cv_param_grid(
#'       n_iterations = c(100, 200),
#'       max_depth = c(3, 5),
#'       learning_rate = c(0.1, 0.5)
#'     ),
#'     n_folds = 5,
#'     n_threads = 1
#'   )
#' )
#'
#' params$df
cv_lightgbm <- function(
    x, y,
    params = cv_param_grid(),
    n_folds = 5,
    n_threads = 1) {
  params <- map_params_lightgbm(params)

  nrow_x <- nrow(x)
  idx_shuffle <- sample(rep_len(seq_len(n_folds), nrow_x))
  df_grid <- expand.grid(
    "num_iterations" = params$num_iterations,
    "max_depth" = params$max_depth,
    "learning_rate" = params$learning_rate,
    "metric" = NA
  )
  idx_grid <- seq_len(nrow(df_grid))
  pb <- progressor(along = idx_grid)

  x <- as.matrix(x)

  pred_probs_list <- foreach(
    idx_param_set = idx_grid,
    .errorhandling = "pass",
    .options.future = list(seed = TRUE)
  ) %dofuture% {
    pb(sprintf("Param set: %d", idx_param_set))

    pred_probs <- matrix(NA, ncol = 2L, nrow = nrow_x)
    colnames(pred_probs) <- c("label", "prob")

    for (idx_fold in seq_len(n_folds)) {
      idx_train <- idx_shuffle != idx_fold
      idx_test <- idx_shuffle == idx_fold

      x_train <- x[idx_train, , drop = FALSE]
      y_train <- y[idx_train]
      x_test <- x[idx_test, , drop = FALSE]
      y_test <- y[idx_test]

      fit <- lightgbm_train(
        data = x_train,
        label = y_train,
        params = list(
          objective = "binary",
          learning_rate = df_grid[idx_param_set, "learning_rate"],
          num_iterations = df_grid[idx_param_set, "num_iterations"],
          max_depth = df_grid[idx_param_set, "max_depth"],
          num_leaves = 2^(df_grid[idx_param_set, "max_depth"]) - 1,
          num_threads = n_threads
        ),
        verbose = -1
      )

      pred_probs[idx_test, "label"] <- y_test
      pred_probs[idx_test, "prob"] <- predict(fit, x_test)
    }

    pred_probs
  }

  for (idx_param_set in idx_grid) {
    df_grid[idx_param_set, "metric"] <- as.numeric(pROC::auc(
      pred_probs_list[[idx_param_set]][, "label"],
      pred_probs_list[[idx_param_set]][, "prob"],
      quiet = TRUE
    ))
  }

  best_row <- which.max(df_grid$metric)
  best_metric <- df_grid$metric[best_row]
  best_num_iterations <- df_grid$num_iterations[best_row]
  best_max_depth <- df_grid$max_depth[best_row]
  best_learning_rate <- df_grid$learning_rate[best_row]

  structure(
    list(
      "df" = df_grid,
      "metric" = best_metric,
      "num_iterations" = best_num_iterations,
      "max_depth" = best_max_depth,
      "learning_rate" = best_learning_rate
    ),
    class = c("cv_params", "cv_lightgbm")
  )
}
